{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. load best model for moleformer, smiles-bert, chemberta;\n",
    "2. load [5, 10, 15, 20] dataset;\n",
    "3. run experiments on different setting, and obtain the auc-roc value for each setting;\n",
    "4. draw the figure of the auc-roc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import auc, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_path = f\"vibtcr/data/result/NAbest\"\n",
    "base_path = 'tc-hard/dataset/few_shot_split/pep+cdr3b'\n",
    "embed_base_path = 'tc-hard/embeddings/few-shot/moleformer' \n",
    "\n",
    "DATA_PATH = \"tc-hard/dataset/few_shot_split/pep+cdr3b\"\n",
    "\n",
    "DICT_PATH = \"tc-hard/meta_data\"\n",
    "\n",
    "negative_generate_mode = \"only-neg-assays\"\n",
    "\n",
    "model_name = \"moleformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def make_df(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    # map_keys = {\n",
    "    # 'cdr3.beta': 'tcrb',\n",
    "    # 'antigen.epitope': 'peptide',\n",
    "    # \"label\": \"label\"\n",
    "    # }\n",
    "    # df = df.rename(columns={c: map_keys[c] for c in df.columns})\n",
    "\n",
    "    df['tcrb'] = df['tcrb'].str.replace('O','X')\n",
    "    df['peptide'] = df['peptide'].str.replace('O','X')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(DICT_PATH, model_name, negative_generate_mode, \"peptide_dict.pkl\"), 'rb') as f:\n",
    "    peptide_embed_dict = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(DICT_PATH, model_name, negative_generate_mode, \"tcrb_dict.pkl\"), 'rb') as f:\n",
    "    tcrb_embed_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(train_df, validation_df, test_df):\n",
    "    tcrb_seq_train = np.vstack(train_df['tcrb'].apply(lambda x: tcrb_embed_dict[x]).values)\n",
    "    tcrb_seq_validation = np.vstack(validation_df['tcrb'].apply(lambda x: tcrb_embed_dict[x]).values)\n",
    "    tcrb_seq_test = np.vstack(test_df['tcrb'].apply(lambda x: tcrb_embed_dict[x]).values)\n",
    "\n",
    "    peptide_seq_train = np.vstack(train_df['peptide'].apply(lambda x: peptide_embed_dict[x]).values)\n",
    "    peptide_seq_validation = np.vstack(validation_df['peptide'].apply(lambda x: peptide_embed_dict[x]).values)\n",
    "    peptide_seq_test = np.vstack(test_df['peptide'].apply(lambda x: peptide_embed_dict[x]).values)\n",
    "\n",
    "    label_seq_train = train_df['label'].values\n",
    "    label_seq_validation = validation_df['label'].values\n",
    "    label_seq_test = test_df['label'].values\n",
    "\n",
    "    # X_train = np.column_stack((tcrb_seq_train, peptide_seq_train))\n",
    "    X_train = np.column_stack((peptide_seq_train, tcrb_seq_train))\n",
    "    y_train = label_seq_train\n",
    "\n",
    "    # X_validation = np.column_stack((tcrb_seq_validation, peptide_seq_validation))\n",
    "    X_validation = np.column_stack((peptide_seq_validation, tcrb_seq_validation))\n",
    "    y_validation = label_seq_validation\n",
    "\n",
    "    # X_test = np.column_stack((tcrb_seq_test, peptide_seq_test))\n",
    "    X_test = np.column_stack((peptide_seq_test, tcrb_seq_test))\n",
    "    y_test = label_seq_test\n",
    "\n",
    "    return X_train, y_train, X_validation, y_validation, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes=[512, 512, 512, 256, 256, 256], dropout=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.BatchNorm1d(hidden_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            layers.append(nn.BatchNorm1d(hidden_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP(input_size = 748 + 500, output_size = 2, hidden_sizes = [32], dropout = 0.3)\n",
    "# model.load_state_dict(torch.load(os.path.join(model_path, \"best_mol-esm_0.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_path = os.path.join(DATA_PATH, \"train\", negative_generate_mode, f\"train-{dataset_index}.csv\")\n",
    "# validation_df_path = os.path.join(DATA_PATH, \"validation\", negative_generate_mode, f\"validation-{dataset_index}.csv\")\n",
    "# test_df_path = os.path.join(DATA_PATH, \"test\", negative_generate_mode, f\"test-{dataset_index}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, dataset_index, best_model_path):\n",
    "    model = MLP(input_size = 480 + 768, output_size = 2, hidden_sizes = [32], dropout = 0.3)\n",
    "    model.load_state_dict(torch.load(os.path.join(best_model_path, f\"best_mol-esm_{dataset_index}.pth\")))\n",
    "    model.to(\"cuda:0\")\n",
    "    model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     test_probabilities = []\n",
    "        # y_true_test = []\n",
    "        # test_running_loss = 0.0\n",
    "        # for test_inputs, test_targets in test_loader:\n",
    "        #     test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "        #     test_outputs = model(test_inputs.float())\n",
    "        #     test_loss = criterion(test_outputs, test_targets)\n",
    "        #     test_running_loss += test_loss.item() * test_inputs.size(0)\n",
    "        #     test_probabilities.extend(torch.softmax(test_outputs, dim=1)[:, 1].cpu().numpy())\n",
    "            # y_true_test.extend(test_targets.cpu().numpy())\n",
    "\n",
    "    y_pred = model(torch.from_numpy(X_test).to(\"cuda:0\"))\n",
    "    test_probabilities = torch.softmax(y_pred, dim=1)[:, 1].detach().cpu().numpy()\n",
    "    y_true_test = y_test\n",
    "    # test_loss = test_running_loss / len(test_loader.dataset)    \n",
    "    test_auc = roc_auc_score(y_true_test, test_probabilities)    \n",
    "    test_predictions = [1 if prob > 0.5 else 0 for prob in test_probabilities]\n",
    "    precision, recall, _ = precision_recall_curve(y_true_test, test_probabilities)\n",
    "    \n",
    "    metrics = {\n",
    "            'AUROC': test_auc,\n",
    "            'Accuracy': accuracy_score(y_true_test, test_predictions),\n",
    "            'Recall': recall_score(y_true_test, test_predictions),\n",
    "            'Precision': precision_score(y_true_test, test_predictions),\n",
    "            'F1 score': f1_score(y_true_test, test_predictions),\n",
    "            'AUPR': auc(recall, precision),\n",
    "        }\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "            'score': list(metrics.values()),\n",
    "            'metrics': list(metrics.keys()),\n",
    "            'experiment': dataset_index\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nBest Model Performance and Evaluation of dataset{dataset_index}:\")\n",
    "    for metric, score in metrics.items():\n",
    "        print(f\"{metric}: {score*100:.4f}%\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, dataset_index, output_model_path):\n",
    "    patience = 20\n",
    "    counter = 0\n",
    "    best_val_roc_auc = 0.0\n",
    "    best_model_path = output_model_path + f\"/best_mol-esm_{dataset_index}.pth\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)  \n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        y_true_val = []\n",
    "        val_probabilities = [] \n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = model(val_inputs.float())\n",
    "                val_loss = criterion(val_outputs, val_targets)\n",
    "                val_running_loss += val_loss.item() * val_inputs.size(0)       \n",
    "                val_probabilities.extend(torch.softmax(val_outputs, dim=1)[:, 1].cpu().numpy())\n",
    "                y_true_val.extend(val_targets.cpu().numpy())  \n",
    "            val_loss = val_running_loss / len(val_loader.dataset)\n",
    "            val_auc = roc_auc_score(y_true_val, val_probabilities)\n",
    "            precision, recall, _ = precision_recall_curve(y_true_val, val_probabilities)\n",
    "            pr_auc = auc(recall, precision)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation AUC: {val_auc:.4f}, PR-AUC: {pr_auc:.4f}')\n",
    "\n",
    "        if val_auc > best_val_roc_auc:\n",
    "            best_val_roc_auc = val_auc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"Saved best model\")\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch}.')\n",
    "                break        \n",
    "        scheduler.step(val_auc)       \n",
    "    print(\"Training complete. Best Val ROC-AUC: {:.4f}\".format(best_val_roc_auc))  \n",
    "        \n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Validation Loss: 0.7311, Validation AUC: 0.9595, PR-AUC: 0.9739\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.8589, Validation AUC: 0.9717, PR-AUC: 0.9852\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.8440, Validation AUC: 0.9696, PR-AUC: 0.9820\n",
      "Epoch [4/10], Validation Loss: 1.1644, Validation AUC: 0.9595, PR-AUC: 0.9791\n",
      "Epoch [5/10], Validation Loss: 0.9477, Validation AUC: 0.9531, PR-AUC: 0.9752\n",
      "Epoch [6/10], Validation Loss: 1.0631, Validation AUC: 0.9642, PR-AUC: 0.9820\n",
      "Epoch [7/10], Validation Loss: 1.5956, Validation AUC: 0.9586, PR-AUC: 0.9809\n",
      "Epoch [8/10], Validation Loss: 1.3291, Validation AUC: 0.9605, PR-AUC: 0.9808\n",
      "Epoch [9/10], Validation Loss: 0.9895, Validation AUC: 0.9578, PR-AUC: 0.9781\n",
      "Epoch [10/10], Validation Loss: 1.4836, Validation AUC: 0.9488, PR-AUC: 0.9760\n",
      "Training complete. Best Val ROC-AUC: 0.9717\n",
      "Epoch [1/10], Validation Loss: 1.4017, Validation AUC: 0.9511, PR-AUC: 0.9805\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.4619, Validation AUC: 0.9176, PR-AUC: 0.9641\n",
      "Epoch [3/10], Validation Loss: 1.4276, Validation AUC: 0.9716, PR-AUC: 0.9885\n",
      "Saved best model\n",
      "Epoch [4/10], Validation Loss: 1.2349, Validation AUC: 0.9514, PR-AUC: 0.9803\n",
      "Epoch [5/10], Validation Loss: 1.1557, Validation AUC: 0.9753, PR-AUC: 0.9902\n",
      "Saved best model\n",
      "Epoch [6/10], Validation Loss: 1.2034, Validation AUC: 0.9755, PR-AUC: 0.9897\n",
      "Saved best model\n",
      "Epoch [7/10], Validation Loss: 1.1054, Validation AUC: 0.9826, PR-AUC: 0.9928\n",
      "Saved best model\n",
      "Epoch [8/10], Validation Loss: 0.8361, Validation AUC: 0.9793, PR-AUC: 0.9913\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [9/10], Validation Loss: 1.2001, Validation AUC: 0.9804, PR-AUC: 0.9921\n",
      "Epoch [10/10], Validation Loss: 1.7101, Validation AUC: 0.9729, PR-AUC: 0.9892\n",
      "Training complete. Best Val ROC-AUC: 0.9826\n",
      "Epoch [1/10], Validation Loss: 1.5554, Validation AUC: 0.9039, PR-AUC: 0.9591\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.1166, Validation AUC: 0.9708, PR-AUC: 0.9884\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 1.5153, Validation AUC: 0.9483, PR-AUC: 0.9797\n",
      "Epoch [4/10], Validation Loss: 1.6058, Validation AUC: 0.9437, PR-AUC: 0.9776\n",
      "Epoch [5/10], Validation Loss: 1.8546, Validation AUC: 0.8348, PR-AUC: 0.9325\n",
      "Epoch [6/10], Validation Loss: 2.2129, Validation AUC: 0.7971, PR-AUC: 0.9175\n",
      "Epoch [7/10], Validation Loss: 2.1066, Validation AUC: 0.8711, PR-AUC: 0.9459\n",
      "Epoch [8/10], Validation Loss: 2.3663, Validation AUC: 0.7655, PR-AUC: 0.9077\n",
      "Epoch [9/10], Validation Loss: 2.2686, Validation AUC: 0.8076, PR-AUC: 0.9226\n",
      "Epoch [10/10], Validation Loss: 2.0583, Validation AUC: 0.8403, PR-AUC: 0.9378\n",
      "Training complete. Best Val ROC-AUC: 0.9708\n",
      "Epoch [1/10], Validation Loss: 0.3432, Validation AUC: 0.9858, PR-AUC: 0.9931\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.3322, Validation AUC: 0.9868, PR-AUC: 0.9936\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.3827, Validation AUC: 0.9876, PR-AUC: 0.9942\n",
      "Saved best model\n",
      "Epoch [4/10], Validation Loss: 0.2997, Validation AUC: 0.9860, PR-AUC: 0.9930\n",
      "Epoch [5/10], Validation Loss: 0.4632, Validation AUC: 0.9863, PR-AUC: 0.9935\n",
      "Epoch [6/10], Validation Loss: 0.6263, Validation AUC: 0.9837, PR-AUC: 0.9923\n",
      "Epoch [7/10], Validation Loss: 0.5559, Validation AUC: 0.9835, PR-AUC: 0.9925\n",
      "Epoch [8/10], Validation Loss: 0.3187, Validation AUC: 0.9874, PR-AUC: 0.9942\n",
      "Epoch [9/10], Validation Loss: 0.5146, Validation AUC: 0.9822, PR-AUC: 0.9920\n",
      "Epoch [10/10], Validation Loss: 0.2225, Validation AUC: 0.9863, PR-AUC: 0.9928\n",
      "Training complete. Best Val ROC-AUC: 0.9876\n",
      "Epoch [1/10], Validation Loss: 0.8517, Validation AUC: 0.9570, PR-AUC: 0.9820\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.4691, Validation AUC: 0.9589, PR-AUC: 0.9831\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.6954, Validation AUC: 0.9678, PR-AUC: 0.9869\n",
      "Saved best model\n",
      "Epoch [4/10], Validation Loss: 0.9315, Validation AUC: 0.9253, PR-AUC: 0.9705\n",
      "Epoch [5/10], Validation Loss: 1.3873, Validation AUC: 0.9127, PR-AUC: 0.9649\n",
      "Epoch [6/10], Validation Loss: 0.7755, Validation AUC: 0.9344, PR-AUC: 0.9750\n",
      "Epoch [7/10], Validation Loss: 0.5898, Validation AUC: 0.9702, PR-AUC: 0.9877\n",
      "Saved best model\n",
      "Epoch [8/10], Validation Loss: 0.9658, Validation AUC: 0.9369, PR-AUC: 0.9759\n",
      "Epoch [9/10], Validation Loss: 1.1711, Validation AUC: 0.9058, PR-AUC: 0.9641\n",
      "Epoch [10/10], Validation Loss: 0.6969, Validation AUC: 0.9602, PR-AUC: 0.9848\n",
      "Training complete. Best Val ROC-AUC: 0.9702\n",
      "Epoch [1/10], Validation Loss: 0.8233, Validation AUC: 0.9703, PR-AUC: 0.9831\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.8237, Validation AUC: 0.9766, PR-AUC: 0.9875\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.8103, Validation AUC: 0.9723, PR-AUC: 0.9841\n",
      "Epoch [4/10], Validation Loss: 1.1203, Validation AUC: 0.9524, PR-AUC: 0.9775\n",
      "Epoch [5/10], Validation Loss: 1.0092, Validation AUC: 0.9733, PR-AUC: 0.9848\n",
      "Epoch [6/10], Validation Loss: 1.1743, Validation AUC: 0.9570, PR-AUC: 0.9771\n",
      "Epoch [7/10], Validation Loss: 1.0750, Validation AUC: 0.9689, PR-AUC: 0.9835\n",
      "Epoch [8/10], Validation Loss: 1.0493, Validation AUC: 0.9676, PR-AUC: 0.9813\n",
      "Epoch [9/10], Validation Loss: 0.7957, Validation AUC: 0.9545, PR-AUC: 0.9692\n",
      "Epoch [10/10], Validation Loss: 0.6842, Validation AUC: 0.9665, PR-AUC: 0.9703\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Training complete. Best Val ROC-AUC: 0.9766\n",
      "Epoch [1/10], Validation Loss: 0.8357, Validation AUC: 0.9817, PR-AUC: 0.9918\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.1246, Validation AUC: 0.9763, PR-AUC: 0.9900\n",
      "Epoch [3/10], Validation Loss: 1.0522, Validation AUC: 0.9771, PR-AUC: 0.9905\n",
      "Epoch [4/10], Validation Loss: 0.9626, Validation AUC: 0.9813, PR-AUC: 0.9918\n",
      "Epoch [5/10], Validation Loss: 1.1697, Validation AUC: 0.9804, PR-AUC: 0.9918\n",
      "Epoch [6/10], Validation Loss: 1.3474, Validation AUC: 0.9742, PR-AUC: 0.9891\n",
      "Epoch [7/10], Validation Loss: 1.3599, Validation AUC: 0.9722, PR-AUC: 0.9880\n",
      "Epoch [8/10], Validation Loss: 1.6125, Validation AUC: 0.9720, PR-AUC: 0.9886\n",
      "Epoch [9/10], Validation Loss: 1.3040, Validation AUC: 0.9699, PR-AUC: 0.9875\n",
      "Epoch [10/10], Validation Loss: 1.0674, Validation AUC: 0.9746, PR-AUC: 0.9894\n",
      "Training complete. Best Val ROC-AUC: 0.9817\n",
      "Epoch [1/10], Validation Loss: 1.2201, Validation AUC: 0.9433, PR-AUC: 0.9757\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.4181, Validation AUC: 0.9473, PR-AUC: 0.9784\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 1.4662, Validation AUC: 0.9289, PR-AUC: 0.9705\n",
      "Epoch [4/10], Validation Loss: 1.4552, Validation AUC: 0.9444, PR-AUC: 0.9768\n",
      "Epoch [5/10], Validation Loss: 2.2461, Validation AUC: 0.8622, PR-AUC: 0.9437\n",
      "Epoch [6/10], Validation Loss: 2.1307, Validation AUC: 0.8136, PR-AUC: 0.9213\n",
      "Epoch [7/10], Validation Loss: 1.6391, Validation AUC: 0.9166, PR-AUC: 0.9659\n",
      "Epoch [8/10], Validation Loss: 1.1244, Validation AUC: 0.9544, PR-AUC: 0.9826\n",
      "Saved best model\n",
      "Epoch [9/10], Validation Loss: 2.0852, Validation AUC: 0.8863, PR-AUC: 0.9538\n",
      "Epoch [10/10], Validation Loss: 1.9498, Validation AUC: 0.8987, PR-AUC: 0.9609\n",
      "Training complete. Best Val ROC-AUC: 0.9544\n",
      "Epoch [1/10], Validation Loss: 0.3890, Validation AUC: 0.9834, PR-AUC: 0.9921\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.3257, Validation AUC: 0.9850, PR-AUC: 0.9921\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.7634, Validation AUC: 0.9826, PR-AUC: 0.9921\n",
      "Epoch [4/10], Validation Loss: 0.4675, Validation AUC: 0.9843, PR-AUC: 0.9922\n",
      "Epoch [5/10], Validation Loss: 0.2981, Validation AUC: 0.9865, PR-AUC: 0.9932\n",
      "Saved best model\n",
      "Epoch [6/10], Validation Loss: 0.3988, Validation AUC: 0.9850, PR-AUC: 0.9926\n",
      "Epoch [7/10], Validation Loss: 0.3912, Validation AUC: 0.9863, PR-AUC: 0.9933\n",
      "Epoch [8/10], Validation Loss: 0.3451, Validation AUC: 0.9867, PR-AUC: 0.9934\n",
      "Saved best model\n",
      "Epoch [9/10], Validation Loss: 0.5969, Validation AUC: 0.9842, PR-AUC: 0.9926\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [10/10], Validation Loss: 0.5318, Validation AUC: 0.9875, PR-AUC: 0.9943\n",
      "Saved best model\n",
      "Training complete. Best Val ROC-AUC: 0.9875\n",
      "Epoch [1/10], Validation Loss: 0.5413, Validation AUC: 0.9694, PR-AUC: 0.9864\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.7726, Validation AUC: 0.9771, PR-AUC: 0.9899\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.9415, Validation AUC: 0.9493, PR-AUC: 0.9796\n",
      "Epoch [4/10], Validation Loss: 1.0264, Validation AUC: 0.9646, PR-AUC: 0.9854\n",
      "Epoch [5/10], Validation Loss: 0.3568, Validation AUC: 0.9706, PR-AUC: 0.9872\n",
      "Epoch [6/10], Validation Loss: 0.7313, Validation AUC: 0.9517, PR-AUC: 0.9807\n",
      "Epoch [7/10], Validation Loss: 0.7786, Validation AUC: 0.9710, PR-AUC: 0.9875\n",
      "Epoch [8/10], Validation Loss: 1.0327, Validation AUC: 0.9252, PR-AUC: 0.9708\n",
      "Epoch [9/10], Validation Loss: 0.9821, Validation AUC: 0.9433, PR-AUC: 0.9774\n",
      "Epoch [10/10], Validation Loss: 0.7395, Validation AUC: 0.9438, PR-AUC: 0.9778\n",
      "Training complete. Best Val ROC-AUC: 0.9771\n",
      "Epoch [1/10], Validation Loss: 0.6466, Validation AUC: 0.9724, PR-AUC: 0.9830\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.8128, Validation AUC: 0.9659, PR-AUC: 0.9751\n",
      "Epoch [3/10], Validation Loss: 0.7015, Validation AUC: 0.9764, PR-AUC: 0.9856\n",
      "Saved best model\n",
      "Epoch [4/10], Validation Loss: 1.2247, Validation AUC: 0.9589, PR-AUC: 0.9774\n",
      "Epoch [5/10], Validation Loss: 1.1547, Validation AUC: 0.9683, PR-AUC: 0.9811\n",
      "Epoch [6/10], Validation Loss: 1.1431, Validation AUC: 0.9615, PR-AUC: 0.9783\n",
      "Epoch [7/10], Validation Loss: 1.1833, Validation AUC: 0.9634, PR-AUC: 0.9795\n",
      "Epoch [8/10], Validation Loss: 0.7589, Validation AUC: 0.9623, PR-AUC: 0.9752\n",
      "Epoch [9/10], Validation Loss: 1.0295, Validation AUC: 0.9730, PR-AUC: 0.9855\n",
      "Epoch [10/10], Validation Loss: 1.0723, Validation AUC: 0.9739, PR-AUC: 0.9838\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Training complete. Best Val ROC-AUC: 0.9764\n",
      "Epoch [1/10], Validation Loss: 1.1080, Validation AUC: 0.9784, PR-AUC: 0.9902\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.3522, Validation AUC: 0.9714, PR-AUC: 0.9881\n",
      "Epoch [3/10], Validation Loss: 1.2469, Validation AUC: 0.9577, PR-AUC: 0.9817\n",
      "Epoch [4/10], Validation Loss: 1.3016, Validation AUC: 0.9742, PR-AUC: 0.9893\n",
      "Epoch [5/10], Validation Loss: 1.2946, Validation AUC: 0.9807, PR-AUC: 0.9919\n",
      "Saved best model\n",
      "Epoch [6/10], Validation Loss: 1.4211, Validation AUC: 0.9773, PR-AUC: 0.9905\n",
      "Epoch [7/10], Validation Loss: 1.1437, Validation AUC: 0.9764, PR-AUC: 0.9903\n",
      "Epoch [8/10], Validation Loss: 1.0133, Validation AUC: 0.9759, PR-AUC: 0.9899\n",
      "Epoch [9/10], Validation Loss: 2.3204, Validation AUC: 0.7919, PR-AUC: 0.8940\n",
      "Epoch [10/10], Validation Loss: 1.0943, Validation AUC: 0.9782, PR-AUC: 0.9910\n",
      "Training complete. Best Val ROC-AUC: 0.9807\n",
      "Epoch [1/10], Validation Loss: 1.5229, Validation AUC: 0.9317, PR-AUC: 0.9710\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.6435, Validation AUC: 0.9523, PR-AUC: 0.9803\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 1.5837, Validation AUC: 0.9034, PR-AUC: 0.9604\n",
      "Epoch [4/10], Validation Loss: 2.0377, Validation AUC: 0.8760, PR-AUC: 0.9461\n",
      "Epoch [5/10], Validation Loss: 1.9391, Validation AUC: 0.9390, PR-AUC: 0.9756\n",
      "Epoch [6/10], Validation Loss: 2.0980, Validation AUC: 0.9116, PR-AUC: 0.9649\n",
      "Epoch [7/10], Validation Loss: 2.1985, Validation AUC: 0.8253, PR-AUC: 0.9290\n",
      "Epoch [8/10], Validation Loss: 2.6213, Validation AUC: 0.8090, PR-AUC: 0.9147\n",
      "Epoch [9/10], Validation Loss: 1.9400, Validation AUC: 0.8744, PR-AUC: 0.9479\n",
      "Epoch [10/10], Validation Loss: 1.7363, Validation AUC: 0.9179, PR-AUC: 0.9674\n",
      "Training complete. Best Val ROC-AUC: 0.9523\n",
      "Epoch [1/10], Validation Loss: 0.4676, Validation AUC: 0.9850, PR-AUC: 0.9924\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.5047, Validation AUC: 0.9860, PR-AUC: 0.9932\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.6547, Validation AUC: 0.9860, PR-AUC: 0.9933\n",
      "Epoch [4/10], Validation Loss: 0.4003, Validation AUC: 0.9843, PR-AUC: 0.9918\n",
      "Epoch [5/10], Validation Loss: 0.2754, Validation AUC: 0.9809, PR-AUC: 0.9898\n",
      "Epoch [6/10], Validation Loss: 0.5819, Validation AUC: 0.9860, PR-AUC: 0.9934\n",
      "Saved best model\n",
      "Epoch [7/10], Validation Loss: 0.8412, Validation AUC: 0.9854, PR-AUC: 0.9932\n",
      "Epoch [8/10], Validation Loss: 0.6023, Validation AUC: 0.9794, PR-AUC: 0.9904\n",
      "Epoch [9/10], Validation Loss: 0.4852, Validation AUC: 0.9816, PR-AUC: 0.9916\n",
      "Epoch [10/10], Validation Loss: 0.4559, Validation AUC: 0.9823, PR-AUC: 0.9911\n",
      "Training complete. Best Val ROC-AUC: 0.9860\n",
      "Epoch [1/10], Validation Loss: 0.8572, Validation AUC: 0.9430, PR-AUC: 0.9765\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.7267, Validation AUC: 0.9636, PR-AUC: 0.9844\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.9515, Validation AUC: 0.9522, PR-AUC: 0.9807\n",
      "Epoch [4/10], Validation Loss: 0.6088, Validation AUC: 0.9661, PR-AUC: 0.9861\n",
      "Saved best model\n",
      "Epoch [5/10], Validation Loss: 0.5816, Validation AUC: 0.9777, PR-AUC: 0.9906\n",
      "Saved best model\n",
      "Epoch [6/10], Validation Loss: 1.0025, Validation AUC: 0.9332, PR-AUC: 0.9727\n",
      "Epoch [7/10], Validation Loss: 0.9307, Validation AUC: 0.9467, PR-AUC: 0.9784\n",
      "Epoch [8/10], Validation Loss: 1.1857, Validation AUC: 0.9474, PR-AUC: 0.9787\n",
      "Epoch [9/10], Validation Loss: 1.4705, Validation AUC: 0.8852, PR-AUC: 0.9553\n",
      "Epoch [10/10], Validation Loss: 0.9358, Validation AUC: 0.9577, PR-AUC: 0.9838\n",
      "Training complete. Best Val ROC-AUC: 0.9777\n",
      "Epoch [1/10], Validation Loss: 0.6532, Validation AUC: 0.9773, PR-AUC: 0.9867\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.9718, Validation AUC: 0.9652, PR-AUC: 0.9759\n",
      "Epoch [3/10], Validation Loss: 1.1869, Validation AUC: 0.9674, PR-AUC: 0.9817\n",
      "Epoch [4/10], Validation Loss: 0.9207, Validation AUC: 0.9655, PR-AUC: 0.9815\n",
      "Epoch [5/10], Validation Loss: 1.5469, Validation AUC: 0.9475, PR-AUC: 0.9733\n",
      "Epoch [6/10], Validation Loss: 1.2164, Validation AUC: 0.9663, PR-AUC: 0.9835\n",
      "Epoch [7/10], Validation Loss: 0.9632, Validation AUC: 0.9613, PR-AUC: 0.9678\n",
      "Epoch [8/10], Validation Loss: 0.9675, Validation AUC: 0.9640, PR-AUC: 0.9775\n",
      "Epoch [9/10], Validation Loss: 1.1229, Validation AUC: 0.9444, PR-AUC: 0.9711\n",
      "Epoch [10/10], Validation Loss: 0.9661, Validation AUC: 0.9665, PR-AUC: 0.9792\n",
      "Training complete. Best Val ROC-AUC: 0.9773\n",
      "Epoch [1/10], Validation Loss: 0.8817, Validation AUC: 0.9742, PR-AUC: 0.9883\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.9199, Validation AUC: 0.9832, PR-AUC: 0.9926\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 1.0926, Validation AUC: 0.9747, PR-AUC: 0.9889\n",
      "Epoch [4/10], Validation Loss: 1.3242, Validation AUC: 0.9630, PR-AUC: 0.9835\n",
      "Epoch [5/10], Validation Loss: 0.8900, Validation AUC: 0.9757, PR-AUC: 0.9896\n",
      "Epoch [6/10], Validation Loss: 1.4076, Validation AUC: 0.9736, PR-AUC: 0.9884\n",
      "Epoch [7/10], Validation Loss: 1.5556, Validation AUC: 0.9698, PR-AUC: 0.9877\n",
      "Epoch [8/10], Validation Loss: 1.5891, Validation AUC: 0.9417, PR-AUC: 0.9723\n",
      "Epoch [9/10], Validation Loss: 1.7862, Validation AUC: 0.9426, PR-AUC: 0.9759\n",
      "Epoch [10/10], Validation Loss: 1.6508, Validation AUC: 0.9718, PR-AUC: 0.9886\n",
      "Training complete. Best Val ROC-AUC: 0.9832\n",
      "Epoch [1/10], Validation Loss: 1.1690, Validation AUC: 0.9243, PR-AUC: 0.9638\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.2917, Validation AUC: 0.9492, PR-AUC: 0.9791\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 2.0874, Validation AUC: 0.8883, PR-AUC: 0.9525\n",
      "Epoch [4/10], Validation Loss: 1.9772, Validation AUC: 0.8443, PR-AUC: 0.9331\n",
      "Epoch [5/10], Validation Loss: 1.4001, Validation AUC: 0.9454, PR-AUC: 0.9764\n",
      "Epoch [6/10], Validation Loss: 1.8100, Validation AUC: 0.9233, PR-AUC: 0.9683\n",
      "Epoch [7/10], Validation Loss: 2.5538, Validation AUC: 0.8456, PR-AUC: 0.9358\n",
      "Epoch [8/10], Validation Loss: 1.4095, Validation AUC: 0.9472, PR-AUC: 0.9783\n",
      "Epoch [9/10], Validation Loss: 2.4208, Validation AUC: 0.8560, PR-AUC: 0.9363\n",
      "Epoch [10/10], Validation Loss: 2.2097, Validation AUC: 0.9083, PR-AUC: 0.9619\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Training complete. Best Val ROC-AUC: 0.9492\n",
      "Epoch [1/10], Validation Loss: 0.2084, Validation AUC: 0.9868, PR-AUC: 0.9931\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.4473, Validation AUC: 0.9859, PR-AUC: 0.9933\n",
      "Epoch [3/10], Validation Loss: 0.4069, Validation AUC: 0.9863, PR-AUC: 0.9931\n",
      "Epoch [4/10], Validation Loss: 0.8704, Validation AUC: 0.9848, PR-AUC: 0.9928\n",
      "Epoch [5/10], Validation Loss: 0.5798, Validation AUC: 0.9833, PR-AUC: 0.9917\n",
      "Epoch [6/10], Validation Loss: 0.5949, Validation AUC: 0.9845, PR-AUC: 0.9924\n",
      "Epoch [7/10], Validation Loss: 0.4591, Validation AUC: 0.9852, PR-AUC: 0.9925\n",
      "Epoch [8/10], Validation Loss: 0.6629, Validation AUC: 0.9861, PR-AUC: 0.9932\n",
      "Epoch [9/10], Validation Loss: 0.6886, Validation AUC: 0.9834, PR-AUC: 0.9920\n",
      "Epoch [10/10], Validation Loss: 0.3934, Validation AUC: 0.9853, PR-AUC: 0.9929\n",
      "Training complete. Best Val ROC-AUC: 0.9868\n",
      "Epoch [1/10], Validation Loss: 0.6631, Validation AUC: 0.9605, PR-AUC: 0.9835\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.6330, Validation AUC: 0.9669, PR-AUC: 0.9860\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 0.9887, Validation AUC: 0.9522, PR-AUC: 0.9810\n",
      "Epoch [4/10], Validation Loss: 1.1180, Validation AUC: 0.9573, PR-AUC: 0.9826\n",
      "Epoch [5/10], Validation Loss: 0.9057, Validation AUC: 0.9572, PR-AUC: 0.9826\n",
      "Epoch [6/10], Validation Loss: 0.8106, Validation AUC: 0.9555, PR-AUC: 0.9824\n",
      "Epoch [7/10], Validation Loss: 0.4629, Validation AUC: 0.9794, PR-AUC: 0.9911\n",
      "Saved best model\n",
      "Epoch [8/10], Validation Loss: 1.2267, Validation AUC: 0.9395, PR-AUC: 0.9753\n",
      "Epoch [9/10], Validation Loss: 1.4440, Validation AUC: 0.9164, PR-AUC: 0.9668\n",
      "Epoch [10/10], Validation Loss: 1.2352, Validation AUC: 0.9336, PR-AUC: 0.9733\n",
      "Training complete. Best Val ROC-AUC: 0.9794\n",
      "Epoch [1/10], Validation Loss: 1.1261, Validation AUC: 0.9732, PR-AUC: 0.9859\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.9068, Validation AUC: 0.9714, PR-AUC: 0.9826\n",
      "Epoch [3/10], Validation Loss: 0.9675, Validation AUC: 0.9699, PR-AUC: 0.9845\n",
      "Epoch [4/10], Validation Loss: 1.1145, Validation AUC: 0.9721, PR-AUC: 0.9850\n",
      "Epoch [5/10], Validation Loss: 1.1609, Validation AUC: 0.9758, PR-AUC: 0.9865\n",
      "Saved best model\n",
      "Epoch [6/10], Validation Loss: 1.3358, Validation AUC: 0.9609, PR-AUC: 0.9796\n",
      "Epoch [7/10], Validation Loss: 1.1659, Validation AUC: 0.9427, PR-AUC: 0.9690\n",
      "Epoch [8/10], Validation Loss: 1.5755, Validation AUC: 0.9512, PR-AUC: 0.9674\n",
      "Epoch [9/10], Validation Loss: 1.2317, Validation AUC: 0.9576, PR-AUC: 0.9720\n",
      "Epoch [10/10], Validation Loss: 0.7249, Validation AUC: 0.9617, PR-AUC: 0.9668\n",
      "Training complete. Best Val ROC-AUC: 0.9758\n",
      "Epoch [1/10], Validation Loss: 0.9214, Validation AUC: 0.9786, PR-AUC: 0.9901\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.1374, Validation AUC: 0.9622, PR-AUC: 0.9840\n",
      "Epoch [3/10], Validation Loss: 1.1133, Validation AUC: 0.9819, PR-AUC: 0.9921\n",
      "Saved best model\n",
      "Epoch [4/10], Validation Loss: 1.6185, Validation AUC: 0.9002, PR-AUC: 0.9561\n",
      "Epoch [5/10], Validation Loss: 1.5155, Validation AUC: 0.9700, PR-AUC: 0.9870\n",
      "Epoch [6/10], Validation Loss: 1.3726, Validation AUC: 0.9748, PR-AUC: 0.9895\n",
      "Epoch [7/10], Validation Loss: 1.6390, Validation AUC: 0.9656, PR-AUC: 0.9860\n",
      "Epoch [8/10], Validation Loss: 1.3705, Validation AUC: 0.9776, PR-AUC: 0.9904\n",
      "Epoch [9/10], Validation Loss: 1.8062, Validation AUC: 0.9520, PR-AUC: 0.9808\n",
      "Epoch [10/10], Validation Loss: 1.7293, Validation AUC: 0.9609, PR-AUC: 0.9838\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Training complete. Best Val ROC-AUC: 0.9819\n",
      "Epoch [1/10], Validation Loss: 1.5189, Validation AUC: 0.8969, PR-AUC: 0.9537\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 1.8099, Validation AUC: 0.9287, PR-AUC: 0.9694\n",
      "Saved best model\n",
      "Epoch [3/10], Validation Loss: 2.3842, Validation AUC: 0.8900, PR-AUC: 0.9541\n",
      "Epoch [4/10], Validation Loss: 1.8232, Validation AUC: 0.9086, PR-AUC: 0.9620\n",
      "Epoch [5/10], Validation Loss: 2.0790, Validation AUC: 0.9061, PR-AUC: 0.9596\n",
      "Epoch [6/10], Validation Loss: 1.8105, Validation AUC: 0.9319, PR-AUC: 0.9726\n",
      "Saved best model\n",
      "Epoch [7/10], Validation Loss: 2.1524, Validation AUC: 0.9165, PR-AUC: 0.9658\n",
      "Epoch [8/10], Validation Loss: 2.0633, Validation AUC: 0.9094, PR-AUC: 0.9607\n",
      "Epoch [9/10], Validation Loss: 2.5285, Validation AUC: 0.8334, PR-AUC: 0.9295\n",
      "Epoch [10/10], Validation Loss: 1.8021, Validation AUC: 0.9416, PR-AUC: 0.9761\n",
      "Saved best model\n",
      "Training complete. Best Val ROC-AUC: 0.9416\n",
      "Epoch [1/10], Validation Loss: 0.4851, Validation AUC: 0.9870, PR-AUC: 0.9936\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.2764, Validation AUC: 0.9862, PR-AUC: 0.9931\n",
      "Epoch [3/10], Validation Loss: 0.6759, Validation AUC: 0.9786, PR-AUC: 0.9901\n",
      "Epoch [4/10], Validation Loss: 0.6159, Validation AUC: 0.9841, PR-AUC: 0.9924\n",
      "Epoch [5/10], Validation Loss: 0.5490, Validation AUC: 0.9836, PR-AUC: 0.9917\n",
      "Epoch [6/10], Validation Loss: 0.5429, Validation AUC: 0.9845, PR-AUC: 0.9925\n",
      "Epoch [7/10], Validation Loss: 0.5872, Validation AUC: 0.9836, PR-AUC: 0.9923\n",
      "Epoch [8/10], Validation Loss: 0.6212, Validation AUC: 0.9836, PR-AUC: 0.9922\n",
      "Epoch [9/10], Validation Loss: 0.7258, Validation AUC: 0.9818, PR-AUC: 0.9916\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [10/10], Validation Loss: 0.9132, Validation AUC: 0.9841, PR-AUC: 0.9928\n",
      "Training complete. Best Val ROC-AUC: 0.9870\n",
      "Epoch [1/10], Validation Loss: 0.8710, Validation AUC: 0.9697, PR-AUC: 0.9877\n",
      "Saved best model\n",
      "Epoch [2/10], Validation Loss: 0.7642, Validation AUC: 0.9601, PR-AUC: 0.9843\n",
      "Epoch [3/10], Validation Loss: 1.1243, Validation AUC: 0.9229, PR-AUC: 0.9695\n",
      "Epoch [4/10], Validation Loss: 0.7287, Validation AUC: 0.9628, PR-AUC: 0.9842\n",
      "Epoch [5/10], Validation Loss: 0.9073, Validation AUC: 0.9535, PR-AUC: 0.9814\n",
      "Epoch [6/10], Validation Loss: 1.1741, Validation AUC: 0.9472, PR-AUC: 0.9788\n",
      "Epoch [7/10], Validation Loss: 0.9178, Validation AUC: 0.9162, PR-AUC: 0.9682\n",
      "Epoch [8/10], Validation Loss: 0.8887, Validation AUC: 0.9444, PR-AUC: 0.9781\n",
      "Epoch [9/10], Validation Loss: 0.7845, Validation AUC: 0.9657, PR-AUC: 0.9860\n",
      "Epoch [10/10], Validation Loss: 0.8482, Validation AUC: 0.9416, PR-AUC: 0.9767\n",
      "Training complete. Best Val ROC-AUC: 0.9697\n"
     ]
    }
   ],
   "source": [
    "for num_few_shot in [20, 100, 150, 200, 300]:\n",
    "    output_model_path = f\"analysis/few-shot/{num_few_shot}\"\n",
    "\n",
    "    for dataset_index in range(5):\n",
    "        if model_name == \"moleformer\":\n",
    "            model = MLP(input_size = 480 + 768, output_size = 2, hidden_sizes = [32], dropout = 0.3)\n",
    "            model.load_state_dict(torch.load(os.path.join(best_model_path, f\"best_mol-esm_{dataset_index}.pth\")))\n",
    "        elif model_name == \"smiles-bert\":\n",
    "            model = MLP(input_size = 480 + 768, output_size = 2, hidden_sizes = [32], dropout = 0.3)\n",
    "            model.load_state_dict(torch.load(\"tc-hard/embeddings/SMILES_BERT/only-neg-assays\"))\n",
    "        elif model_name == \"ChemBERTa\":\n",
    "            model = MLP(input_size = 480 + 384, output_size = 2, hidden_sizes = [32], dropout = 0.3)\n",
    "            model.load_state_dict(torch.load(f\"best_mol-esm_{dataset_index}.pth\"))\n",
    "        model = model.to(\"cuda:0\")\n",
    "\n",
    "\n",
    "        train_df_path = os.path.join(DATA_PATH, \"train\", negative_generate_mode, f\"{num_few_shot}-train-{dataset_index}.csv\")\n",
    "        validation_df_path = os.path.join(DATA_PATH, \"validation\", negative_generate_mode, f\"{num_few_shot}-validation-{dataset_index}.csv\")\n",
    "        test_df_path = os.path.join(DATA_PATH, \"test\", negative_generate_mode, f\"{num_few_shot}-test-{dataset_index}.csv\")\n",
    "\n",
    "        train_df = make_df(train_df_path)\n",
    "        validation_df = make_df(validation_df_path)\n",
    "        test_df = make_df(test_df_path)\n",
    "\n",
    "        X_train, y_train, X_validation, y_validation, X_test, y_test = get_embeddings(train_df, validation_df, test_df)\n",
    "            \n",
    "        train_dataset = TensorDataset(torch.from_numpy(X_train), torch.tensor(y_train))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_dataset = TensorDataset(torch.from_numpy(X_validation), torch.tensor(y_validation))\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_dataset = TensorDataset(torch.from_numpy(X_test), torch.tensor(y_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)    \n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.001)  \n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1, verbose=True)\n",
    "        \n",
    "        train_model(model, train_loader, val_loader, 10, criterion, optimizer, scheduler, device, dataset_index, output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Performance and Evaluation of dataset0:\n",
      "AUROC: 98.2542%\n",
      "Accuracy: 99.8827%\n",
      "Recall: 99.9923%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9413%\n",
      "AUPR: 99.9981%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset1:\n",
      "AUROC: 98.1221%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9976%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset2:\n",
      "AUROC: 90.7713%\n",
      "Accuracy: 99.8852%\n",
      "Recall: 99.9949%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9426%\n",
      "AUPR: 99.9893%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset3:\n",
      "AUROC: 98.1205%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9979%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset4:\n",
      "AUROC: 93.0345%\n",
      "Accuracy: 99.8291%\n",
      "Recall: 99.9387%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9145%\n",
      "AUPR: 99.9920%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset0:\n",
      "AUROC: 96.4357%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9960%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset1:\n",
      "AUROC: 85.2396%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9815%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset2:\n",
      "AUROC: 94.6884%\n",
      "Accuracy: 99.7603%\n",
      "Recall: 99.8698%\n",
      "Precision: 99.8902%\n",
      "F1 score: 99.8800%\n",
      "AUPR: 99.9940%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset3:\n",
      "AUROC: 97.7803%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9975%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset4:\n",
      "AUROC: 93.1081%\n",
      "Accuracy: 99.8623%\n",
      "Recall: 99.9719%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9311%\n",
      "AUPR: 99.9920%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset0:\n",
      "AUROC: 96.3945%\n",
      "Accuracy: 99.8852%\n",
      "Recall: 99.9949%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9426%\n",
      "AUPR: 99.9959%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset1:\n",
      "AUROC: 97.4695%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9970%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset2:\n",
      "AUROC: 96.2753%\n",
      "Accuracy: 99.8776%\n",
      "Recall: 99.9872%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9388%\n",
      "AUPR: 99.9957%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset3:\n",
      "AUROC: 96.2973%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9958%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset4:\n",
      "AUROC: 96.5717%\n",
      "Accuracy: 99.3012%\n",
      "Recall: 99.3873%\n",
      "Precision: 99.9127%\n",
      "F1 score: 99.6493%\n",
      "AUPR: 99.9961%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset0:\n",
      "AUROC: 97.2441%\n",
      "Accuracy: 99.8750%\n",
      "Recall: 99.9847%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9375%\n",
      "AUPR: 99.9969%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset1:\n",
      "AUROC: 98.6167%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9984%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset2:\n",
      "AUROC: 92.8728%\n",
      "Accuracy: 99.8597%\n",
      "Recall: 99.9694%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9298%\n",
      "AUPR: 99.9918%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset3:\n",
      "AUROC: 97.9392%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9977%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset4:\n",
      "AUROC: 90.5605%\n",
      "Accuracy: 99.8240%\n",
      "Recall: 99.9336%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9119%\n",
      "AUPR: 99.9890%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset0:\n",
      "AUROC: 98.7544%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9986%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset1:\n",
      "AUROC: 98.3392%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9981%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset2:\n",
      "AUROC: 92.6534%\n",
      "Accuracy: 99.8240%\n",
      "Recall: 99.9336%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9119%\n",
      "AUPR: 99.9915%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset3:\n",
      "AUROC: 97.0104%\n",
      "Accuracy: 99.8903%\n",
      "Recall: 100.0000%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9451%\n",
      "AUPR: 99.9966%\n",
      "\n",
      "Best Model Performance and Evaluation of dataset4:\n",
      "AUROC: 97.6392%\n",
      "Accuracy: 99.8750%\n",
      "Recall: 99.9847%\n",
      "Precision: 99.8903%\n",
      "F1 score: 99.9375%\n",
      "AUPR: 99.9973%\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    \"score\": [],\n",
    "    \"metrics\": [],\n",
    "    \"experiment\": [] \n",
    "})\n",
    "l = []\n",
    "for num_few_shot in [20, 100, 150, 200, 300]:\n",
    "    output_model_path = f\"analysis/few-shot/{num_few_shot}\"\n",
    "    for dataset_index in range(5):\n",
    "        l.append(evaluate_and_save(model, dataset_index, output_model_path))\n",
    "\n",
    "    result_df = pd.concat(l)\n",
    "    # print(result_df)\n",
    "    result_df.to_csv(f\"few-shot-result/{num_few_shot}_result.csv\")\n",
    "    \n",
    "    stats = result_df.groupby('metrics')['score'].agg(['mean', 'std']).reset_index()\n",
    "    stats.to_csv(f\"few-shot-result/{num_few_shot}_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUPR</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>8.294838e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUROC</td>\n",
       "      <td>0.929772</td>\n",
       "      <td>6.655524e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.998880</td>\n",
       "      <td>5.651287e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>2.828822e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>6.022991e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>5.657316e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     metrics      mean           std\n",
       "0       AUPR  0.999916  8.294838e-05\n",
       "1      AUROC  0.929772  6.655524e-02\n",
       "2   Accuracy  0.998880  5.651287e-05\n",
       "3   F1 score  0.999440  2.828822e-05\n",
       "4  Precision  0.998934  6.022991e-08\n",
       "5     Recall  0.999945  5.657316e-05"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group data by 'metrics' and calculate the mean and standard deviation for 'score'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: 0.901\n",
    "\n",
    "20% seen\n",
    "\n",
    "1: 0.924796\n",
    "\n",
    "2: 0.948553\n",
    "\n",
    "3: 0.947340\n",
    "\n",
    "4: 0.944642\n",
    "\n",
    "5: 0.907792 / 0.931580\n",
    "\n",
    "10: 0.907764 / 0.933113\n",
    "\n",
    "15: 0.907747 / 0.929772\n",
    "\n",
    "20: 0.907721 / 0.956605\n",
    "\n",
    "100: 0.907400 / 0.945554\n",
    "\n",
    "150: 0.907151 / 0.952375\n",
    "\n",
    "200: 0.906876 / 0.952898\n",
    "\n",
    "300: 0.904357 / 0.956077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
